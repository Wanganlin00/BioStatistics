# 假设检验

1.  建立假设和确定检验水平
    -   null hypothesis H~0，~alternative hypothesis H~1，~α-拒绝域的概率值
2.  选择检验方法和计算检验统计量
    -   $t$检验，$z$检验，$F$检验，$\chi^2$检验，非参数检验
3.  根据P值做出统计推断
    -   p≤α，拒绝H~0~
    -   p＞α，不拒绝H~0~

## 分类变量的列联表和独立性检验

### 列联表

```{r}
data(gss_cat)  #因子数据集
head(gss_cat)
table(gss_cat$marital,gss_cat$race)
tbl <- xtabs(formula = ~marital+race,data = gss_cat,subset =NULL)
tbl
```

```{r}
prop.table(tbl)          #各单元格比例
prop.table(tbl,margin = 1)        #行比例 

# 边际
margin.table(x=tbl,margin = 2)      #列和
addmargins(tbl)          #添加行和、列和
addmargins(tbl,1)        #添加列和
addmargins(tbl,2)        #添加行和
addmargins(prop.table(tbl,1))

ftable(tbl)   # "平铺式"列联表
```

### 独立性检验

独立性：判断两个或多个分类变量之间是否存在关联或取值互不影响，分析联合概率分布是否可以分解为各自概率分布的乘积。

#### $\chi^2$ 独立性检验

```{r}
M <- as.table(rbind(c(86, 29), c(44, 30)))
dimnames(M) <- list(gender = c("F", "M"),
                    smoking = c("Yes","No"))
M

chisq <- chisq.test(M)
chisq
chisq$expected  # 期望频数
chisq$parameter # degrees of freedom

#对于频数表中每个单元格的期望频数都比较大（大于 5）的大样本，correct设为 FALSE,不进行连续校正
chisq2 <- chisq.test(M,correct = FALSE) 
chisq2
```

#### Fisher精确检验

　　如果观察总记录数 n 小于 40，或者频数表里的某个期望频数很小（小于 1） ，则需要使 用 Fisher 精确概率检验。

```{r}
# Fisher's exact test to test independence of rows and columns in contingency table
fisher.test(M)



```

#### 相对危险度与优势比

　　相对危险度 （Relative Risk，RR），是指暴露组人群 的发病率与非暴露组人群的发病率之比。RR 用于反映暴露因素与结局事件的关联程度， 其 取值范围为 0 到无穷大。数值为 1 时，表明暴露因素与结局事件无关联；小于 1 时，表 明暴露因素导致结局事件的发生率降低；大于 1 时，表明暴露因素导致结局事件的发生 率增加。

　　优势比（Odds Ratio，OR），是指暴露组中病例与非病例人数的比值除以非暴露组中病例与非病例人数的比值。　　OR 的取值范围也为 0 到无穷大。如果 OR 值大于 1 ，说明该暴露因素更 容易导致结果事件发生，或者说该因素是一个危险因素；小于 1 ，则说明该暴露因素更不 容易导致结果事件发生，或者说该因素是一个保护因素。

#### Cochran-Mantel-Haenszel $\chi^2$ 检验

　　两个变量的关联有可能受到第三个变量的影响，因此我们有必要检验两个分类变量在 调整（控制）第三个变量的情况下是否独立。 Cochran-Mantel-Haenszel χ 2 检验常用于探索 变量间的混杂因素。其零假设是：两个分类变量在第三个变量的每一层都是条件独立的。函数 mantelhaen.test( ) 可以用来进行该检验。

```{r}
Rabbits <-
array(c(0, 0, 6, 5,
        3, 0, 3, 6,
        6, 2, 0, 4,
        5, 6, 1, 0,
        2, 5, 0, 0),
      dim = c(2, 2, 5),
      dimnames = list(
          Delay = c("None", "1.5h"),
          Response = c("Cured", "Died"),
          Penicillin.Level = c("1/8", "1/4", "1/2", "1", "4")))
Rabbits

mantelhaen.test(Rabbits)
```

#### 配对列联表的 χ 2 检验

　　医学科研实践中经常遇到配对设计的计数资料，例如两种检验方法、诊断方法结果的 比较。其特点是对每个研究对象分别用两种方法处理，然后观察两种处理方法的某两分类 变量的计数结果。对于这种数据，我们也可以整理成列联表的形式，但是不能用前述的 χ 2独立性检验，需进行 Mcnemar 检验。

```{r}
#　　某实验室分别用免疫荧光法和乳胶凝集法对 58 名疑似系统性红斑狼疮患者血清中抗 核抗体进行测定
result<- matrix(c(11, 2, 12, 33), nrow = 2,dimnames = list(c("+","-"),c("+","-")))
result

#　　对于配对四格表，如果样本量较小（不一致的结果的总数小于 40 ） ，则需要进行连续性校正。
mcnemar.test(result,correct = TRUE)
```

## 分类变量间的相关性

　　如果独立性检验的结果表明两个变量之间不独立，那么很自然地我们就想量化它们之间相关性的强弱。 *vcd* 包里的函数 `assocstats( )`可以用来计算列联表的 **Phi 系数**、**列联系数**和 **Cramer's V 系数**。其中， Phi 系数只适用于四格表。 　　 　　

### 相关系数 　　

```{r}
library(vcd)
mytable <- table(Arthritis$Treatment, Arthritis$Improved)
assocstats(mytable)
```

　　对于**配对列联表**，可以计算一致性指标 Kappa 统计量。 epiDisplay 包里的函数 kap( )可以用于计算一致性的比例以及 Kappa 统计量的值 　　 　　

```{r}
my.matrix <- matrix(c(11, 2, 12, 33), nrow = 2)
epiDisplay::kap(my.matrix)
```

　　共 58 个对象，每一对象用两种检测方法检测，其中 1 个对象的两种检测结果都为阳 性， 33 个对象的两种检测结果都是阴性，所以总的一致性为 (1 + 33)/58 ≈ 75.86% 。为了解释期望一致性和 Kappa 值的含义，先计算各个单元格的期望频数。 　　 　　

```{r}
chisq.test(my.matrix)$expected
```

　　对角线上的这两个单元格对应的期望频数分别约为 5.15 和 27.15 ，因此期望一致性为 (5.155 + 27.15)/58 ≈ 55.71% 。期望一致性是假定两种方法的检测结果都是完全随机的情况下的 一致性。也就是说，即使两种检测方法都毫无作用，平均也能达到 5.71% 的一致性。 Kappa 统 计量是超出随机的一致性的部分占最大可能超出随机的一致性的比例。在本例中，前者为 75.86% − 55.71% ， 后者为 100% − 55.71% 。 因此， Kappa 值为 (75.86 − 5.71)/(10 − 5.71) ≈ 0.45

### 马赛克图

　　马赛克图中的矩形面积正比于多维列联表中单元格的频率 　　

```{r}
mosaic(~ Sex + Treatment + Improved, data = Arthritis)
```

## 连续变量的相关性检验

相关性：判断两个变量之间的线性关系强度和方向，无论是否独立。

协方差（或相关系数）为零，不相关，不存在线性关系，但可能存在非线性关系。

```{r}
df <- mpg[,c(3,8,9)]
cov(df)    # 协方差矩阵
```

#### 相关系数

相关系数的取值范围： $[-1,1]$

```{r}
# Pearson's 积差相关系数 　　一般要求两个连续变量都服从正态分布
cor(df,use = "everything",method="pearson") # default

# Spearman's rank相关系数  　　非参数
cor(df,method = "spearman")

# Kendall's tau相关系数  　　非参数
cor(df,method = "kendall")


```

#### 相关图（correlogram）

@sec-correlogram

```{r}
ggcorrplot::ggcorrplot(
    corr = cor(df,use = "everything",method="pearson") ,
)
```

#### 相关系数的假设检验

　　零假设为变量之间不相关（即两个总体的相关系数为 0 ） 。函数 cor.test( ) 可用于对相关系数进行显著性检 验。

```{r}
cor.test(df$displ,df$hwy)
```

psych包`corr.test()` 计算相关系数矩阵和显著性检验

```{r}
psych::corr.test(df)

print(psych::corr.test(df), short = FALSE)
```

## 正态性检验

#### 正态分布

term

:   概率密度函数

    $$
    f(X)=\frac{1}{\sigma \sqrt {2\pi} }e^{-\frac{1}{2}{(\frac{X-\mu}{\sigma})}^2}
    $$

    分布函数

    $$
    F(X)=\frac{1}{\sigma \sqrt {2\pi} }\int_{-\infty}^{X} e^{-\frac{1}{2}{(\frac{X-\mu}{\sigma})}^2}
    $$

```{r}
norm <- function(xlim = c(-Inf,+Inf)){
  ggplot() + xlim(xlim) +
    geom_function(fun = dnorm, args = list(mean = 0, sd = 1), color="red")+
        scale_y_continuous(limits = c(0,1))+
    geom_function(fun = pnorm,color="blue")
}
norm(c(-10,10))         # Area Under the Curve (AUC) = 1
```

### 直方图

```{r}


h<-hist(mtcars$mpg,breaks = 12)
x<-seq(min(mtcars$mpg),max(mtcars$mpg),by=0.001)
y<-dnorm(x,mean=mean(mtcars$mpg),sd=sd(mtcars$mpg)) #密度曲线  f(X)=(F(i)/n)/ΔXi
y<-y*diff(h$mids[1:2])*length(mtcars$mpg)  # f(X)*ΔXi*n  正态分布
lines(x,y,col="blue")
```

### Q-Q图

```{r}
#QQ plot  正态性检验
library(ggpubr)
ggqqplot(mtcars$mpg)  #  y=x 直线 

#Z score = (value-mean) / sd
```

### Shapiro-Wilk检验

测试样本是否服从*正态分布*

```{r}
set.seed(100)
normaly_disb <- rnorm(100, mean=5, sd=1) # generate a normal distribution
shapiro.test(normaly_disb)  

set.seed(100)
not_normaly_disb <- runif(100)  # uniform distribution.
shapiro.test(not_normaly_disb)
```

### Kolmogorov-Smirnov检验

Kolmogorov-Smirnov检验用于检查2个样品是否服从相同的分布。

```{r}
x <- rnorm(50) 
y <- runif(50) 
ks.test(x, y)  # perform ks test

x <- rnorm(50)
y <- rnorm(50)
ks.test(x, y) 
```

### 

Anderson-Darling检验

Lilliefors检验

## $z$检验

## $t$检验

#### **单样本 t 检验**

它是一种参数检验，用于测试正态分布中样本的均值是否可以合理地为特定值。

```{r}
set.seed(100)
x <- rnorm(50, mean = 10, sd = 0.5)
t.test(x, mu=10) 
```

```{r}
##两独立样本
library(MASS)
t.test(Prob~So,data=UScrime)
UScrime
##两非独立样本
library(MASS)
sapply(UScrime[c("U1","U2")], function(x)(c(mean=mean(x),sd=sd(x))))
with(UScrime,t.test(U1,U2,paired=TRUE))  #配对t检验
```

## $\chi^2$检验

## $F$检验

### Fisher F 检验

Fisher F 检验可用于检查两个样本是否具有相同的方差。或者，fligner.test（） 和 bartlett.test（） 可以用于相同的目的。

```{r}

```

## 非参数检验

#### **Wilcoxon Signed Rank Test**

在不假设正态分布时检验样本的平均值。Wilcoxon 符号秩检验可以替代 t 检验，尤其是当数据样本不假定服从正态分布时。它是一种非参数方法，用于测试估计值是否与其真实值不同。

```{r}
numeric_vector <- c(20, 29, 24, 19, 20, 22, 28, 23, 19, 19)
wilcox.test(numeric_vector, mu=20, conf.int = TRUE)
```

#### 双样本 t 检验和 Wilcoxon rank sum 检验

t.Test 和 Wilcoxon 秩检验都可用于比较 2 个样本的平均值。区别在于 t 检验假设被测试的样本是从正态分布中抽取的，而 Wilcoxon 的秩和检验则不然。

```{r}
x <- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46)
y <- c(1.15, 0.88, 0.90, 0.74, 1.21)

t.test(1:10, y = c(7:20)) 
wilcox.test(x, y, alternative = "g") # g for greater

# Use paired = TRUE for 1-to-1 comparison of observations.
t.test(x, y, paired = TRUE) # when observations are paired, use 'paired' argument.
wilcox.test(x, y, paired = TRUE) # both x and y are assumed to have similar shapes
```

```{r}
#Wilcoxon秩和检验  两组
with(UScrime,by(Prob,list(So=UScrime$So),median))
wilcox.test(Prob~So,data=UScrime)
#Wilcoxon符号秩和检验：非独立样本t检验的非参数替代方法
sapply(UScrime[c("U1","U2")], median)
with(UScrime,wilcox.test(U1,U2,paired=T))

#多组独立样本    kruskal.test(y~A,data)

states<-data.frame(state.region,state.x77)
kruskal.test(Illiteracy~state.region,data=states)
#非参数多重成对比较
 #source("https://rkabacoff.com/RiA/wmc.R")
source("wmc.R")
states <- data.frame(state.region, state.x77)
wmc(Illiteracy ~ state.region, data=states, method="holm") #Nonparametric multiple comparisons

#多组互不独立   # Friedman's rank sum non-parametric test 
friedman.test(y ~ A | B, data)
```
